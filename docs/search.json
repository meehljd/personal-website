[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "About Me",
    "section": "",
    "text": "Hey there! I’m Josh Meehl, a Data Scientist with a passion for where engineering meets science. I thrive on asking the “why” questions to understand systems, then putting on my engineering hat to scale solutions efficiently and reliably."
  },
  {
    "objectID": "index.html#what-i-do",
    "href": "index.html#what-i-do",
    "title": "About Me",
    "section": "What I Do",
    "text": "What I Do\nI specialize in data science and bioinformatics, applying cutting-edge data science techniques to solve complex problems in the biotech sector. My work ranges from predicting enzyme function with large language models to optimizing next-generation sequencing workflows using graph convolutional networks."
  },
  {
    "objectID": "index.html#my-approach",
    "href": "index.html#my-approach",
    "title": "About Me",
    "section": "My Approach",
    "text": "My Approach\nI love diving into the intersection of technology and life sciences. Whether it’s developing ML pipelines for protein engineering or creating predictive models for oligo production, I’m always excited to leverage data to drive meaningful impact."
  },
  {
    "objectID": "index.html#projects",
    "href": "index.html#projects",
    "title": "About Me",
    "section": "Projects",
    "text": "Projects\nHere’s a quick reference to some of my recent projects:\n\nProtein Engineering Pipeline: Developed an ML-based pipeline for enzyme development using large language models (LLMs) and optimization algorithms.\nSimulated Annealing Optimization: Applied simulated annealing algorithms to optimize the traveling salesperson problem with a whimsical twist.\nCOVID-19 cDNA Clustering: Analyzed and clustered cDNA sequences to understand mutation patterns in SARS-CoV-2.\nOligo Production Failure Prediction: Enhanced predictive models for oligo production failures, leading to improved margins and reduced production failures."
  },
  {
    "objectID": "index.html#outside-work",
    "href": "index.html#outside-work",
    "title": "About Me",
    "section": "Outside Work",
    "text": "Outside Work\nWhen I’m not immersed in bioinformatics, I channel my data science passion into a unique project: analyzing Magic: The Gathering (MTG) on my website The Data Mage. Here, I apply advanced data science and machine learning techniques to explore the intricacies of this complex card game. From predictive modeling of card interactions to optimizing deck-building strategies using ML algorithms, this project showcases how data-driven approaches can provide novel insights into recreational activities.\nI’m always eager to learn and stay updated with the latest in tech and data science. Let’s connect and explore how we can push the boundaries of what’s possible with data!"
  },
  {
    "objectID": "projects/simulated-annealing.html",
    "href": "projects/simulated-annealing.html",
    "title": "Annealing of Nations: Where Kids’ Music Meets Optimization Algorithms",
    "section": "",
    "text": "One challenge with having little ones is finding kids’ music that doesn’t slowly drive you crazy. My family enjoys the kids’ albums by the nerd rock group They Might Be Giants (TMBG). Their song “Alphabet of Nations” is quite catchy.\nAt the same time my family was listening to the TMBG albums, I was also studying optimization and search heuristics. I was fascinated by the traveling salesman problem (TSP) and the various algorithms used to solve it.\nAnd so, in a moment of what I can only describe as sleep-deprived inspiration (parents, you know what I’m talking about), I decided to combine these two seemingly unrelated interests. The result? A project that uses the Simulated Annealing algorithm to solve a Traveling Salesperson Problem based on the nations mentioned in TMBG’s “Alphabet of Nations”. Because why not?"
  },
  {
    "objectID": "projects/simulated-annealing.html#the-challenge",
    "href": "projects/simulated-annealing.html#the-challenge",
    "title": "Annealing of Nations: Where Kids’ Music Meets Optimization Algorithms",
    "section": "The Challenge",
    "text": "The Challenge\nThe task was straightforward, if a bit eccentric: find the most efficient route to visit all the countries listed in the song. Here’s our illustrious itinerary:\nAlgeria, Bulgaria, Cambodia, Dominica, Egypt, France, Gambia, Hungary, Iran, Japan, Kazakhstan, Libya, Mongolia, Norway, Oman, Pakistan, Qatar, Russia, Suriname, Turkey, Uruguay, Vietnam, Xylokeriza (Greece), Yemen, Zimbabwe\nYou might notice that “Xylokeriza, Greece” seems out of place. That’s because the song actually mentions “West Xylophone”, which, last I checked, isn’t a recognized nation. Since “xylophone” is of Greek origins, I substituted it with a real place in Greece that has “xylo” in the name. Creative problem-solving at its finest.\nFor those curious about the musical inspiration behind this madness, you can find the video here. Just don’t blame me if it gets stuck in your head."
  },
  {
    "objectID": "projects/simulated-annealing.html#the-results",
    "href": "projects/simulated-annealing.html#the-results",
    "title": "Annealing of Nations: Where Kids’ Music Meets Optimization Algorithms",
    "section": "The Results",
    "text": "The Results\nAfter letting the algorithm run, here’s what it came up with:\n\n\n\nFinal trip route.\n\n\nAnd because no good project is complete without a graph, here’s how our trip cost evolved over time:\n\n\n\nCost of trip per iteration.\n\n\nAs you can see, we started with costs ranging from $9,000 to $15,000 per person. Thankfully, our trusty algorithm managed to bring it down to a more reasonable $6,000. Still not cheap, but hey, that’s the price of combining data science and musical geography."
  },
  {
    "objectID": "projects/simulated-annealing.html#the-method-to-the-madness",
    "href": "projects/simulated-annealing.html#the-method-to-the-madness",
    "title": "Annealing of Nations: Where Kids’ Music Meets Optimization Algorithms",
    "section": "The Method to the Madness",
    "text": "The Method to the Madness\nFor those interested in the technical details (and let’s face it, if you’ve read this far, you probably are), here’s how I put this together:\n\nFlight Data\nI repurposed some code from a previous project, the “Flight Deal Finder”, because why solve one problem when you can solve two? This code does the following:\n\nChoosing the busiest airport in each country.\nCreating a Google Sheet with these airports.\nUsing the Tiquila API via Kiwi.com to get flight prices, with some arbitrary rules to keep things interesting:\n\nCheapest one-way flights with up to 3 layovers\nFlight dates within 6 months of the query date\n\n\n\n\nOptimization\nThis is where the Simulated Annealing algorithm comes in. If you’re not familiar with it, imagine the process of forging a sword. Imagine heating metal to a high temperature so it becomes malleable, then slowly cooling it while hammering to remove imperfections. In simulated annealing, the “temperature” controls how freely the algorithm explores possible solutions, starting with random, wide exploration (high temperature) and gradually focusing on improving solutions (lower temperature). Just like how a blacksmith avoids cooling the metal too quickly to prevent cracks, the algorithm reduces randomness gradually to find an optimal solution without getting stuck in suboptimal ones. But here, instead of a sword, we have a travel itinerary. For the curious (or the insomniacs), there’s always the Wikipedia page.\nThe algorithm will randomly swap a pair of airports to change the route and compare the results to the previous route. If the new paths do not have available flights, the new route is rejected. If the new route is cheaper, it is kept. If the new route is more expensive, it is rejected with some probability of keeping it, based on the relative difference in the two routes’ performance, as well as the temperature parameter.\n\n\n\nTemperature Schedule"
  },
  {
    "objectID": "projects/simulated-annealing.html#whats-next",
    "href": "projects/simulated-annealing.html#whats-next",
    "title": "Annealing of Nations: Where Kids’ Music Meets Optimization Algorithms",
    "section": "What’s Next?",
    "text": "What’s Next?\nHaving completed this project, I find myself at a crossroads. Do I:\n\nExpand on this, perhaps finding the optimal route for other music-inspired challenges? (Beach Boy’s Kokomo, anyone?)\nUse my newfound skills for something practical, like a trip optimizer app?\nFinally get some sleep?\n\nOnly time will tell. In the meantime, if you have any suggestions for improvements or just want to commiserate about the intersection of parenting, music, and data science, feel free to reach out. I’ll be here, probably humming “Alphabet of Nations” and dreaming of efficient flight paths."
  },
  {
    "objectID": "projects/covid-seq-clustering.html",
    "href": "projects/covid-seq-clustering.html",
    "title": "Covid Sequence Clustering",
    "section": "",
    "text": "In this project, I compare machine learning techniques for clustering of SARS-CoV-2 cDNA sequences by variants.\nAt this point the whole world has had a crash course in virology, but to recap, the SARS-CoV-2 virus is an RNA virus. These types of viruses often mutate, due to the relative instability of RNA sequences. This results in many strains of the virus, some of which are more infectious than others.\nFor those who want to dive deeper into the nitty-gritty details, you can find the notebooks in the GitHub repository."
  },
  {
    "objectID": "projects/covid-seq-clustering.html#the-challenge",
    "href": "projects/covid-seq-clustering.html#the-challenge",
    "title": "Covid Sequence Clustering",
    "section": "The Challenge",
    "text": "The Challenge\nThere are two items we need to address with clustering of cDNA sequences. First, we need to find a way to compare the sequences. Second, we need to find a way to group the sequences. This is a classic unsupervised learning problem.\nTo challenge myself, I will implement clustering solutions I currently use. Typically I would first do a literature search to find state-of-the-art approaches, but want to solve this problem with my own approaches.\nAlso, I will avoid libraries like Biopython that are specifically designed for bioinformatics. Instead I will use raw python and numpy to manipulate sequences. For the linear algebra of the clustering techniques, I will use solely numpy and only use sklearn for some convenience functions. Again, this is to challenge myself to implement algorithms from scratch where I would typically use 3rd party libraries. This is reinventing the wheel, but sometimes it’s worth it to get that sense of accomplishment."
  },
  {
    "objectID": "projects/covid-seq-clustering.html#the-data",
    "href": "projects/covid-seq-clustering.html#the-data",
    "title": "Covid Sequence Clustering",
    "section": "The Data",
    "text": "The Data\nThe data I have is multi-sequence alignment (MSA) of 400 SARS-CoV-2 sequences in a fasta file. The sequences are of complementary DNA, sequenced from viral RNA that has undergone reverse transcriptase. The sequences are from sample that originate from an unknown number of strains.\nEach location of the sequences can have the four nucleotides A, C, G, or T. A position could also have a N if the nucleotide was indeterminate or a - if there was no sequence data at that position. The sequences have been aligned and fully conserved regions replaced with the symbol .."
  },
  {
    "objectID": "projects/covid-seq-clustering.html#the-method",
    "href": "projects/covid-seq-clustering.html#the-method",
    "title": "Covid Sequence Clustering",
    "section": "The Method",
    "text": "The Method\nTo cluster the sequences, I first needed to clean the data. Next I needed to find a similarity measure to compare the sequences. Then I used a variety of clustering algorithms to group the sequences.\n\nData Cleaning\nI used python to parse the fasta file. I then converted the 400 sequences into a numpy array with the characters converted to integers. This gave me a 400 x 34,044 array.\nThis left me with sequences that contained missing (-) or indeterminate (N) data. If a given MSA position had less that 5% missing data, I imputed the missing data with the most common nucleotide at that position. If a position had more than 5% missing data, I removed the sequence from the dataset. This resulted with the typical sequence having 1-2% of the positions imputed.\nAt this point I also dropped all fully conserved positions (.), as they would not contribute to the clustering. This left me with a 400 x 17,463 array.\n\n\n\n\n\n\n\n\n\n\n\n(a) Raw MSA\n\n\n\n\n\n\n\n\n\n\n\n(b) Cleaned MSA\n\n\n\n\n\n\n\nFigure 1: Visualization of MSA sequences before and after cleaning, showing first 500 positions. (a) is color scaled to have missing or fully conserved values in black and other values in lighter gray. (b) is rescaled to have A in white and T in black.\n\n\n\nNext I calculated the entropy of the MSA for each position. This gives us an idea of how variable the sequence positions are. We get a sense of baseline noise of random mutations, as well as positions that have low conservation across major strains.\nNote for the entropy calculation, I used \\(log_4\\) to account for the number of nucleotides, although hte convention is \\(log_2\\) for bits. To me this makes more sense, since DNA is quaternary, not binary.\n\n\n\nEntropy per MSA position. Zoomed to show detail.\n\n\nMost positions are fully conserved with an entropy of 0. Some positions have small entropy values, representing positions that are conserved with occasional random mutations. Some positions have high entropy values, representing positions that are highly variable and may indicate mutations across major strains.\nNext I plotted a histogram of the entropy values to visualize the random mutations versus the major strain mutations. We can see below the distribution is multimodal. I put a cutoff threshold at 0.145, which is at the right tail of the random mutation distribution. This cutoff will be used to filter out positions that are not conserved across major strains. Future work could look at fitting a mixture model to the entropy distribution to find the optimal cutoff.\n\n\n\nHistogram of the entropy per MSA position. The left mode is random mutations and the other modes are mutations of major strains.\n\n\nAfter trimming the MSA to remove low entropy positions, I was left with a 400 x 110 array. This is a good size for clustering, as it is a good balance between having enough data to find clusters and not having too much data to be computationally expensive.\n\n\n\nVisualization of MSA sequences after trimming. Color scale based on A (lightest), C, G, T (darkest).\n\n\n\n\nSimilarity Measure\nNow onto the exciting world of similarity measures! The next step in clustering will be to generate a similarity data structure from the sequence data. I will use the Hamming distance as the distance metric. This is a good distance metric for sequences since it works with discrete categorical data. For a pair of sequences, the Hamming distance will be the number of positions where the sequences have different nucleotides.\nThe trick with Hamming distance is that it gives us a relative similarity between sequence pairs, but not on an absolute scale. We can address this issue by building a graph of the sequences, using the similarity as edge weights. This gives us a good sense of the local structure of the data. We will represent the graph as an adjacency matrix.\nTo provide cleaner results, I made the dense adjacency matrix sparse. Only the nearest 75 neighbors to a sequence node are retained. The rest are dropped.\n\n\nClustering Algorithms\nThe next step is to cluster the graph. I have two ideas for this, using different perspectives.\nThe first perspective is to use linear algebra to find a low dimensional representation. We can cluster on the eigenvectors with the lowest eigenvalues. This approach is called spectral clustering.\nThe second perspective is to treat the neighborhood graph as a low dimensional manifold in high-dimensional space. I will use the manifold learning algorithm ISOMAP to calculate a low-dimensional representation that preserves the geodesic distances and then cluster.\nFor the clustering algorithm, I will use \\(k\\)-means. I will also implement my own version of \\(k\\)-means from scratch in numpy to challenge myself.\n\nSpectral Clustering\nFor spectral clustering I will first convert the adjacency matrix into a Laplacian matrix, which allows use to have at least one eigenvalue equal to zero.\nI tried both the standard Laplacian, \\(L = D - A\\), and the normalized Laplacian, \\(L = D^{-/frac{1}{2}} /cdot A /cdot D^{-/frac{1}{2}}\\). Here \\(D\\) is the distance matrix which is a diagonal matrix that sums the weights of the adjacency matrix. I found the standard Laplacian worked better for this application.\nFor clustering, I used classic \\(k\\)-means. I validated the choice of \\(k\\) with visualizations of the elbow diagram, adjacency matrix, MSA sequences, and eigenvectors.\n\n\nClustering with ISOMAP\nFor the ISOMAP, I calculated the geodesic distance matrix \\(D2\\) from the graph by finding the shortest path between each pair of sequences. I next center the matrix using the centering matrix \\(H\\). We then select the \\(n\\) largest eigenvalues to perform multidimensional reductions (MDS), resulting in a reduced representation matrix \\(Z\\).\nI cluster the matrix \\(Z\\) with \\(k\\)-means and then validate the clusters like with spectral clustering."
  },
  {
    "objectID": "projects/covid-seq-clustering.html#the-results",
    "href": "projects/covid-seq-clustering.html#the-results",
    "title": "Covid Sequence Clustering",
    "section": "The Results",
    "text": "The Results\nBoth approaches find 5 major strains of SARS-CoV-2 sequences. As we increase the \\(k\\) value, the major strains clusters get subdivided into outlier sequences and sub-strain clusters.\n\n\n\n\n\n\n\n\n\n\n\n(a) Spectral Clustering\n\n\n\n\n\n\n\n\n\n\n\n(b) ISOMAP\n\n\n\n\n\n\n\nFigure 2: Elbow diagrams for spectral clustering and ISOMAP. Both show a break at 5 \\(k\\)=5.\n\n\n\n\nSpectral Clustering\nIf we look at the adjacency matrix for spectral clustering, we can see the effects of the number of clusters. It make five clusters well. Going beyond five clusters, we see the most heterogenous cluster breaking into into sub-clusters.\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(k\\)=1\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(k\\)=5\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(k\\)=7\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(k\\)=9\n\n\n\n\n\n\n\nFigure 3: Adjacency matrix after spectral clustering for \\(k\\) clusters.\n\n\n\nLooking at the sequences, we again see that there are 5 major strains, with each strain having different levels of heterogeneity.\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(k\\)=1\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(k\\)=5\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(k\\)=7\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(k\\)=9\n\n\n\n\n\n\n\nFigure 4: MSA sequences after sorting for the \\(k\\) spectral clusters.\n\n\n\nWe can also look at the clusters in the reduced spectral space. Eigenvectors 1 and 2 show good separation among the 5 clusters. On eigenvector 4, we see separation of one cluster into sub-clusters.\n\n\n\n\n\n\n\n\n\n\n\n(a) Eigenvectors 1 & 2\n\n\n\n\n\n\n\n\n\n\n\n(b) Eigenvectors 4 & 2\n\n\n\n\n\n\n\nFigure 5: Visualization of the eigenvectors. Color coded by cluster where \\(k=7\\). Note the subdivision of sub-clusters on the left of eigenvector 4.\n\n\n\n\n\nISOMAP\nThe ISOMAP results are similar to the spectral clustering result. We see 5 major strains, with each strain having different levels of heterogeneity. At \\(k\\)=9, the ISOMAP does a better job of separating the sub-strains, as we can see in the geodesic distance matrix below.\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(k\\)=1\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(k\\)=5\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(k\\)=7\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(k\\)=9\n\n\n\n\n\n\n\nFigure 6: Geodesic distance matrix after ISOMAP for \\(k\\) clusters.\n\n\n\nNext we can see the clustering of the sequences.\n\n\n\n\n\n\n\n\n\n\n\n(a) \\(k\\)=1\n\n\n\n\n\n\n\n\n\n\n\n(b) \\(k\\)=5\n\n\n\n\n\n\n\n\n\n\n\n(c) \\(k\\)=7\n\n\n\n\n\n\n\n\n\n\n\n(d) \\(k\\)=9\n\n\n\n\n\n\n\nFigure 7: MSA sequences after sorting for the \\(k\\) ISOMAP clusters.\n\n\n\nWe can visualize the clusters in the reduced ISOMAP space. We see good separation among the 5 clusters, with further separation of some sub-clusters when \\(k\\)=7.\n\n\n\nVisualization of the ISOMAP reduced dimensions. Color coded by cluster where \\(k=7\\)."
  },
  {
    "objectID": "projects/covid-seq-clustering.html#conclusion",
    "href": "projects/covid-seq-clustering.html#conclusion",
    "title": "Covid Sequence Clustering",
    "section": "Conclusion",
    "text": "Conclusion\nBoth the spectral clustering and ISOMAP approaches worked well for clustering the SARS-CoV-2 sequences. Both approaches found 5 major strains, with each strain having different levels of heterogeneity. The ISOMAP approach did a better job of separating the sub-strains. Further validation could be performed by using labeled data with strain information.\nFurther work could be done to identify the sensitive of the results to the data cleaning thresholds. Also, the entropy cutoff could be optimized by fitting a mixture model to the entropy distribution. Finally, the clustering algorithms could be optimized for speed and memory usage.\nThe clustering of the strains also raises questions of phylogeny. The clustering could be used to build a phylogenetic tree of the strains. This could be done by using the Hamming distance as a measure of genetic distance between the strains. The tree could be built using a variety of phylogenetic tree algorithms, such as UPGMA or neighbor joining. Or we could drop clustering altogether and model the viral evolution as part of a Ornstein-Uhlenbeck process with stochastic differential equations.\nI hope this project has given you a good overview of how to cluster cDNA sequences. If you have any questions or suggestions, please feel free to reach out to me."
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Resume",
    "section": "",
    "text": "Your browser does not support PDFs. Download the PDF to view it: Download PDF."
  },
  {
    "objectID": "projects/protein-engineering.html",
    "href": "projects/protein-engineering.html",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "",
    "text": "Protein engineering is a fascinating field at the intersection of biology, chemistry, and computer science. It involves the design and modification of proteins to create new or enhanced functionalities. In this project, I explored the potential of using advanced machine learning models to improve the process of developing new proteins with enhanced properties.\nThis project was my practicum for my master’s degree in analytics at Georgia Tech, where I applied my data science skills to the field of protein engineering. You can view the full technical report here."
  },
  {
    "objectID": "projects/protein-engineering.html#the-challenge",
    "href": "projects/protein-engineering.html#the-challenge",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "The Challenge",
    "text": "The Challenge\nThe task was to develop a computational pipeline to efficiently identify superior protein variants for a diverse set of proteins. This challenge is crucial in many areas of biotechnology, from developing new enzymes for industrial processes to creating better therapeutics.\nThe main obstacles in protein engineering are:\n\nThe high cost and time requirements of experimental testing. Ideally we can reduce the number of experiments needed to find the best protein variant. This also means we will typically have little or no functional data to start with.\nThe complex relationship between protein sequence and function. This is where LLM type models can really shine. We need to be able to predict a protein’s function given its sequence.\nThe vast search space of possible protein sequences. This is like finding a needle in a haystack the size of the universe. This is called the “combinatorial explosion” problem. We need to find the optimal protein variants in this massive fitness landscape.\n\nMy goal was to use machine learning to navigate this complex landscape more efficiently, reducing the time and resources needed to discover improved protein variants.\n\n\n\nThe 3 main steps in my computational pipeline."
  },
  {
    "objectID": "projects/protein-engineering.html#the-method",
    "href": "projects/protein-engineering.html#the-method",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "The Method",
    "text": "The Method\nFor those interested in the technical details, here’s how I approached this challenge:\n\nData: I used a dataset of 34 deep mutational scanning (DMS) studies, spanning 25 organisms and various protein functions.\nZero-shot Learning: I employed the Evolutionary Scale Modeling (ESM) family of transformer-based protein language models developed by Facebook AI Research. These models can make predictions about protein function without any experimental data.\nFew-shot Learning: Using the DMS experimental data, I trained various regression models (k-nearest neighbors, support vector machines, random forests, and ridge regression) on embeddings from the PLMs.\nGaussian Processes: To balance exploration and exploitation in my search for superior variants, I implemented Gaussian Process models that provide both predictions and uncertainty estimates.\nBayesian Optimization: I used a simplified Bayesian optimization approach to efficiently search the protein fitness landscape, leveraging the uncertainties provided by the GP models."
  },
  {
    "objectID": "projects/protein-engineering.html#the-results",
    "href": "projects/protein-engineering.html#the-results",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "The Results",
    "text": "The Results\nAfter developing and testing my computational pipeline, I found some key insights.\nZero-shot learning achieved a median Spearman rank correlation of ρ ≈ 0.52 between predicted and actual protein functionality.\n\n\n\nCorrelation between actual and predicted functional rank of zero-shot predictions for an example protein.\n\n\nZero-shot learning with protein language models (PLMs) can reduce the effort required to find superior protein variants by nearly 50%.\n\n\n\nNumber of rounds to get top variants in DMS dataset of zero-shot predictions for an example protein.\n\n\nFew-shot learning with the simple regression algorithms under-performs zero-shot learning. This is likely due to the small number of data points available for training.\n\n\n\nNumber of rounds to get top variants in DMS dataset of few-shot regression algorithms for an example protein.\n\n\nThe Gaussian Process (GP) regression models start to outperform zero-shot predictions with more data, typically around 300 data points. The GP also outperforms the other few-shot simple regression models.\n\n\n\nGP prediction performance as data draining size increases\n\n\nAs modeled, using Bayesian Optimization (BO) with Gaussian Processes did not have a large improvement over point estimates. This bears further investigating.\n\n\n\nNumber of rounds to get top variants in DMS dataset for an example protein using BO"
  },
  {
    "objectID": "projects/protein-engineering.html#whats-next",
    "href": "projects/protein-engineering.html#whats-next",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "What’s Next?",
    "text": "What’s Next?\nHaving completed this project, there are several exciting directions to explore:\n\nExpand the approach to a wider range of proteins and functions, potentially uncovering general principles of protein engineering.\nIntegrate structural information into the models to improve prediction accuracy.\nDevelop more sophisticated Bayesian optimization strategies for navigating the fitness landscape.\nApply this pipeline to real-world challenges in enzyme engineering or therapeutic protein design.\n\nRecently the ProteinGym was launched. It is a website that contains a collection of benchmarks and leaderboards for comparing models that predict protein mutation effects. It is the protein equivalent of Papers With Code. It is also a source of more mutational data, with DMS substitutions and indels, as well as mutational clinical data."
  },
  {
    "objectID": "projects/protein-engineering.html#technical-details",
    "href": "projects/protein-engineering.html#technical-details",
    "title": "Protein Engineering: Harnessing Machine Learning for Molecular Design",
    "section": "Technical Details",
    "text": "Technical Details\nFor those who want to dive deeper into the nitty-gritty details, here is the Practicum Final Report. It includes all the mathematical formulas, model architectures, and performance metrics for a comprehensive understanding of the project.\nThis project demonstrates the power of machine learning in accelerating protein engineering. By combining state-of-the-art language models with clever optimization strategies, we can dramatically reduce the time and cost associated with developing new protein variants. As these techniques continue to evolve, they promise to revolutionize fields from industrial biotechnology to personalized medicine."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "I’m open to discussing new projects, collaborations, or opportunities. Please feel free to reach out!\n\n\n\nEmail: joshua@meehl.org\nPhone: 320-224-5017\n\n\n\n\n\n LinkedIn\n GitHub\n mage.meehl.org\n\n\n\n\n\nYour Name: \nYour Email: \nYour Message:\n\n\nSend"
  },
  {
    "objectID": "contact.html#direct-contact",
    "href": "contact.html#direct-contact",
    "title": "Contact",
    "section": "",
    "text": "Email: joshua@meehl.org\nPhone: 320-224-5017"
  },
  {
    "objectID": "contact.html#connect-online",
    "href": "contact.html#connect-online",
    "title": "Contact",
    "section": "",
    "text": "LinkedIn\n GitHub\n mage.meehl.org"
  },
  {
    "objectID": "contact.html#send-a-message",
    "href": "contact.html#send-a-message",
    "title": "Contact",
    "section": "",
    "text": "Your Name: \nYour Email: \nYour Message:\n\n\nSend"
  }
]